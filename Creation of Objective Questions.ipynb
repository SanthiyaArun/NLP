{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60fbc0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\admin\\anaconda3\\envs\\akaike\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\admin\\anaconda3\\envs\\akaike\\lib\\site-packages (from nltk) (8.1.6)\n",
      "Requirement already satisfied: joblib in c:\\users\\admin\\anaconda3\\envs\\akaike\\lib\\site-packages (from nltk) (1.3.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\admin\\anaconda3\\envs\\akaike\\lib\\site-packages (from nltk) (2023.6.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\admin\\anaconda3\\envs\\akaike\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\anaconda3\\envs\\akaike\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9776c0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdfplumber in c:\\users\\admin\\anaconda3\\envs\\akaike\\lib\\site-packages (0.10.2)\n",
      "Requirement already satisfied: pdfminer.six==20221105 in c:\\users\\admin\\anaconda3\\envs\\akaike\\lib\\site-packages (from pdfplumber) (20221105)\n",
      "Requirement already satisfied: Pillow>=9.1 in c:\\users\\admin\\anaconda3\\envs\\akaike\\lib\\site-packages (from pdfplumber) (10.0.0)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in c:\\users\\admin\\anaconda3\\envs\\akaike\\lib\\site-packages (from pdfplumber) (4.18.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\admin\\anaconda3\\envs\\akaike\\lib\\site-packages (from pdfminer.six==20221105->pdfplumber) (3.2.0)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\admin\\anaconda3\\envs\\akaike\\lib\\site-packages (from pdfminer.six==20221105->pdfplumber) (41.0.3)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\admin\\anaconda3\\envs\\akaike\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber) (1.15.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\admin\\anaconda3\\envs\\akaike\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber) (2.21)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3b4d01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from itertools import combinations\n",
    "import pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0075e114",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download required resources for NLTK\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4784e483",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        text = \"\"\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "430d3b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mca_questions(context: str):\n",
    "    # Split the context into sentences\n",
    "    sentences = sent_tokenize(context)\n",
    "\n",
    "    # Tokenize each sentence into words\n",
    "    sentences_tokens = [word_tokenize(sentence) for sentence in sentences]\n",
    "\n",
    "    # Remove stopwords and punctuation\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    cleaned_sentences = []\n",
    "    for sentence_tokens in sentences_tokens:\n",
    "        cleaned_sentence = [word.lower() for word in sentence_tokens if word.isalpha() and word.lower() not in stop_words]\n",
    "        cleaned_sentences.append(cleaned_sentence)\n",
    "\n",
    "    # Generate combinations of cleaned sentences to create questions\n",
    "    mca_questions = []\n",
    "    for i, j in combinations(range(len(cleaned_sentences)), 2):\n",
    "        q1 = \" \".join(cleaned_sentences[i])\n",
    "        q2 = \" \".join(cleaned_sentences[j])\n",
    "        mca_question = f\"Q: Which of the following are true about {q1}?\"\n",
    "        mca_question += f\"\\na. {q1}\"\n",
    "        mca_question += f\"\\nb. {q2}\"\n",
    "        mca_questions.append(mca_question)\n",
    "\n",
    "    return mca_questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7230956a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"chapter-2.pdf\"\n",
    "pdf_text = extract_text_from_pdf(pdf_path)\n",
    "mca_questions = get_mca_questions(pdf_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b79dd140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the MCQs in a Python (.py) file\n",
    "with open(\"mca_questions.py\", \"w\") as py_file:\n",
    "    py_file.write(\"mca_questions = [\\n\")\n",
    "    for idx, question in enumerate(mca_questions):\n",
    "        py_file.write(f'    \"Q{idx+1}: {question}\",\\n')\n",
    "    py_file.write(\"]\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5b4f57",
   "metadata": {},
   "source": [
    "Step 1: Import required libraries\n",
    "- The code starts by importing the necessary libraries and modules.\n",
    "- `nltk` is the Natural Language Toolkit, used for text processing and tokenization.\n",
    "- `pdfplumber` is the library we'll use for PDF text extraction.\n",
    "- `itertools.combinations` is imported for generating combinations of elements.\n",
    "\n",
    "Step 2: Download NLTK resources\n",
    "- The code then downloads the required NLTK resources for text processing. These resources include tokenizers, stopwords, etc.\n",
    "\n",
    "Step 3: Define the function `extract_text_from_pdf(pdf_path)`\n",
    "- This function takes the file path of a PDF as input and returns the extracted text from the PDF.\n",
    "- `pdfplumber.open(pdf_path)` opens the PDF file using `pdfplumber` and returns a PDF object.\n",
    "- The `with` statement ensures that the PDF object is properly closed after processing.\n",
    "- The function iterates through each page of the PDF using `pdf.pages`.\n",
    "- For each page, it extracts the text using `page.extract_text()` and appends it to the `text` variable.\n",
    "- Finally, the function returns the concatenated text from all the pages.\n",
    "\n",
    "Step 4: Define the function `get_mca_questions(context: str)`\n",
    "- This function takes a text context as input and generates multiple-choice questions based on the content.\n",
    "- The rest of the function contains the same code as before, which generates MCA questions based on the provided context. The details of the MCA question generation are not shown in the code snippet you provided, but I assume it involves some text processing and analysis to create the questions.\n",
    "\n",
    "Step 5: Example Usage\n",
    "- The code demonstrates an example usage of the functions.\n",
    "- It sets the `pdf_path` variable to the path of the PDF file you want to process.\n",
    "- It then calls the `extract_text_from_pdf` function with `pdf_path` as input, which extracts the text from the PDF.\n",
    "- The extracted text is then passed to the `get_mca_questions` function, which generates multiple-choice questions based on the text context.\n",
    "- Finally, it prints the generated questions using a loop.\n",
    "\n",
    "Overall, the code performs the following tasks:\n",
    "1. Imports necessary libraries.\n",
    "2. Downloads NLTK resources.\n",
    "3. Defines a function to extract text from a PDF file using `pdfplumber`.\n",
    "4. Defines a function to generate multiple-choice questions based on a given text context (though the details of question generation are not provided in the snippet).\n",
    "5. Demonstrates example usage by extracting text from a PDF and generating multiple-choice questions based on that text."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
